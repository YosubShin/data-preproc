# Simple filtering configuration that preserves original dataset structure
# Uses HF Datasets .filter() method for efficient filtering without transformation

base_model: Qwen/Qwen2.5-7B-Instruct
tokenizer_config: Qwen/Qwen2.5-7B-Instruct
trust_remote_code: true
sequence_len: 16384

dataset_prepared_path: ./data/prepared

datasets:
  - path: yosubshin/WaltonMultimodalColdStart-without-image-1k-1
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # First filter by image count
      # - type: image_count_filter
      #   min_images: 1 # Filter out samples with less than 1
      #   max_images: 1 # Filter out samples with more than 1

      # # Resize images larger than 768px down to 768px max
      # - type: image_transform
      #   max_size: [768, 768]
      #   resize_mode: "keep_aspect_ratio"

      # - type: hf_filter
      #   max_tokens: 13500 # Filter by tokenized length
      #   min_tokens: 200 # Min meaningful content
      #   filter_corrupted_images: true # Remove corrupted images
      #   min_image_size: [32, 32]
      #   text_fields: ["solution"] # Fields to tokenize for length check

      # - type: random_sampler
      #   sample_size: 1800
      #   seed: 42

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "problem" # Deduplicate based on question field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 8 # N-gram size for token-level comparison
        external_datasets:
          - path: "yosubshin/OlympiadBench-1k"
            subset: "_ALL"
            split: "train"
            column: "question"

          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          - path: "yosubshin/LiveXivVQA-1k"
            split: "train"
            column: "problem"

          - path: "yosubshin/LiveXivTQA-1k"
            split: "train"
            column: "problem"

      - type: random_sampler
        sample_size: 900
        seed: 42
  
  - path: yosubshin/cosyn-with-traces
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # - type: random_sampler
      #   sample_size: 200
      #   seed: 42

      # # First filter by image count
      # - type: image_count_filter
      #   min_images: 1 # Filter out samples with less than 1
      #   max_images: 1 # Filter out samples with more than 1

      # - type: longest_explanation_mapping
      #   question_field: question
      #   explanation_field: explanation
      #   answer_field: answer
      #   problem_field: problem
      #   solution_field: solution
      #   keep_unmapped: true
      #   remove_source_fields: true

      - type: advanced_mapping
        keep_unmapped: false         # start from a clean dict
        mappings:
          - source: image
            target: image
          - source: problem
            target: problem
          - source: reasoning_trace
            target: solution

      # - type: hf_filter
      #   max_tokens: 13500 # Filter by tokenized length
      #   # min_tokens: 750 # Min meaningful content
      #   filter_corrupted_images: true # Remove corrupted images
      #   min_image_size: [32, 32]
      #   text_fields: ["solution"] # Fields to tokenize for length check

      - type: random_sampler
        sample_size: 100
        seed: 42

train_on_inputs: false
val_set_size: 0
batch_size: 8

# HF upload
hf_upload:
  enabled: true
  organization: "yosubshin"
  dataset_name: "walton-without-image-cosyn-traces"
  private: false
  description: "Combined Walton (without image), CoSyn-400K"
  license: "apache-2.0"
  tags: ["vision-language", "filtered"]
  create_readme: true
