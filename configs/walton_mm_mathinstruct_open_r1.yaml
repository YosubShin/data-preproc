# Simple filtering configuration that preserves original dataset structure
# Uses HF Datasets .filter() method for efficient filtering without transformation

base_model: Qwen/Qwen2.5-7B-Instruct
tokenizer_config: Qwen/Qwen2.5-7B-Instruct
trust_remote_code: true
sequence_len: 16384

dataset_prepared_path: ./data/prepared

datasets:
  - path: oumi-ai/walton-multimodal-cold-start-r1-format
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 200 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "solution" # Deduplicate based on solution field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 15 # N-gram size for token-level comparison
        external_datasets:
          # Deduplicate against OlympiadBench
          - path: "Hothan/OlympiadBench"
            subset: "_ALL"
            split: "train"
            column: "solution"

          # Deduplicate against VMCBench
          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          # Deduplicate against LiveXiv-VLMEvalKit
          - path: "penfever/LiveXiv-VLMEvalKit"
            split: "train"
            column: "question"

      # Random downsampling to 5,000 samples
      - type: random_sampler
        sample_size: 5000
        seed: 42

  - path: oumi-ai/MM-MathInstruct-to-r1-format-filtered
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # Convert image format to HuggingFace Image type for compatibility
      - type: image_format_converter
        image_fields: ["image"]
        target_format: "hf_image"

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"
        # to_pil: true

      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 200 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "solution" # Deduplicate based on solution field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 15 # N-gram size for token-level comparison
        external_datasets:
          # Deduplicate against OlympiadBench
          - path: "Hothan/OlympiadBench"
            subset: "_ALL"
            split: "train"
            column: "solution"

          # Deduplicate against VMCBench
          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          # Deduplicate against LiveXiv-VLMEvalKit
          - path: "penfever/LiveXiv-VLMEvalKit"
            split: "train"
            column: "question"

          - path: "oumi-ai/walton-multimodal-cold-start-r1-format"
            split: "train"
            column: "solution"

      - type: column_mapping
        column_mapping:
          # old_name: new_name
          solution: solution_with_think
          original_answer: solution

      # Random downsampling to 2,500 samples
      - type: random_sampler
        sample_size: 2500
        seed: 42
  - path: oumi-ai/multimodal-open-r1-8192-filtered-mid-ic
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"
        # to_pil: true

      # Convert image format to HuggingFace Image type for compatibility
      - type: image_format_converter
        image_fields: ["image"]
        target_format: "hf_image"

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 200 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "solution" # Deduplicate based on solution field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 15 # N-gram size for token-level comparison
        external_datasets:
          # Deduplicate against OlympiadBench
          - path: "Hothan/OlympiadBench"
            subset: "_ALL"
            split: "train"
            column: "solution"

          # Deduplicate against VMCBench
          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          # Deduplicate against LiveXiv-VLMEvalKit
          - path: "penfever/LiveXiv-VLMEvalKit"
            split: "train"
            column: "question"

          - path: "oumi-ai/walton-multimodal-cold-start-r1-format"
            split: "train"
            column: "solution"

          - path: "oumi-ai/MM-MathInstruct-to-r1-format-filtered"
            split: "train"
            column: "solution"

      - type: column_mapping
        column_mapping:
          # old_name: new_name
          solution: solution_with_think
          original_answer: solution

      # Random downsampling to 2,500 samples
      - type: random_sampler
        sample_size: 2500
        seed: 42

train_on_inputs: false
val_set_size: 0
batch_size: 8

# HF upload
hf_upload:
  enabled: true
  organization: "yosubshin"
  dataset_name: "walton-mm-mathinstruct-open-r1"
  private: false
  description: "Combined Walton, Math MInstruct, and Open R1"
  license: "apache-2.0"
  tags: ["vision-language", "filtered"]
  create_readme: true
