# Simple filtering configuration that preserves original dataset structure
# Uses HF Datasets .filter() method for efficient filtering without transformation

base_model: Qwen/Qwen2.5-7B-Instruct
tokenizer_config: Qwen/Qwen2.5-7B-Instruct
trust_remote_code: true
sequence_len: 16384

dataset_prepared_path: ./data/prepared

datasets:
  - path: yosubshin/WaltonMultimodalColdStart-hard
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 200 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      - type: random_sampler
        sample_size: 1800
        seed: 42

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "problem" # Deduplicate based on question field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 8 # N-gram size for token-level comparison
        external_datasets:
          - path: "yosubshin/OlympiadBench-1k"
            subset: "_ALL"
            split: "train"
            column: "question"

          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          - path: "yosubshin/LiveXivVQA-1k"
            split: "train"
            column: "problem"

          - path: "yosubshin/LiveXivTQA-1k"
            split: "train"
            column: "problem"

      - type: random_sampler
        sample_size: 900
        seed: 42
  
  - path: oumi-ai/MM-MathInstruct-to-r1-format-filtered
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # Convert image format to HuggingFace Image type for compatibility
      - type: image_format_converter
        image_fields: ["image"]
        target_format: "hf_image"

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"
        # to_pil: true

      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 750 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      - type: random_sampler
        sample_size: 100
        seed: 42

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "problem" # Deduplicate based on question field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 8 # N-gram size for token-level comparison
        external_datasets:
          - path: "yosubshin/OlympiadBench-1k"
            subset: "_ALL"
            split: "train"
            column: "question"

          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          - path: "yosubshin/LiveXivVQA-1k"
            split: "train"
            column: "problem"

          - path: "yosubshin/LiveXivTQA-1k"
            split: "train"
            column: "problem"

      - type: column_mapping
        column_mapping:
          # old_name: new_name
          solution: solution_with_think
          original_answer: solution

      - type: random_sampler
        sample_size: 50
        seed: 42

  - path: yosubshin/mmr1-10k-long
    type: vision_language # Still need this for file path generation
    split: train
    filter_only: true # Skip tokenization strategy - just filter and save

    # Use HF filter processor that preserves original structure
    processors:
      # First filter by image count
      - type: image_count_filter
        min_images: 1 # Filter out samples with less than 1
        max_images: 1 # Filter out samples with more than 1

      # Resize images larger than 768px down to 768px max
      - type: image_transform
        max_size: [768, 768]
        resize_mode: "keep_aspect_ratio"

      - type: hf_filter
        max_tokens: 13500 # Filter by tokenized length
        min_tokens: 750 # Min meaningful content
        filter_corrupted_images: true # Remove corrupted images
        min_image_size: [32, 32]
        text_fields: ["solution"] # Fields to tokenize for length check

      - type: random_sampler
        sample_size: 100
        seed: 42

      # Deduplication against external datasets and itself
      - type: deduplicator
        method: "combined" # Use both fuzzy and n-gram methods
        column: "problem" # Deduplicate based on question field
        similarity_threshold: 98.0 # Similarity threshold (0-100)
        ngram_size: 8 # N-gram size for token-level comparison
        external_datasets:
          - path: "yosubshin/OlympiadBench-1k"
            subset: "_ALL"
            split: "train"
            column: "question"

          - path: "suyc21/VMCBench"
            split: "dev"
            column: "question"

          - path: "yosubshin/LiveXivVQA-1k"
            split: "train"
            column: "problem"

          - path: "yosubshin/LiveXivTQA-1k"
            split: "train"
            column: "problem"

      - type: random_sampler
        sample_size: 50
        seed: 42

train_on_inputs: false
val_set_size: 0
batch_size: 8

# HF upload
hf_upload:
  enabled: true
  organization: "yosubshin"
  dataset_name: "walton-hard-mm-mathinstruct-mmr1-long-1k"
  private: false
  description: "Combined Walton (hard), MM-MathInstruct (long), MMR1 (long), 1k samples"
  license: "apache-2.0"
  tags: ["vision-language", "filtered"]
  create_readme: true
